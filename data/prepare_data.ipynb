{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "381113d4-cf83-4177-a672-32ec9a45cdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to create a Transformer model which would eventually emits pathways.\n",
    "# For that we download all GSEA pathways  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "919c308a-9b70-4731-9a09-5c04dc09ee5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math \n",
    "from collections import Counter\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "b3553a73-076f-473c-8bdb-6a054f71d66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse .gmt file and return a list of all unique genes\n",
    "def parse_gmt_file(filepath):\n",
    "    genesets = {}\n",
    "    with open(filepath, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split('\\t') # Assuming tab-delimited .gmt file\n",
    "            gene_set_name = parts[0]\n",
    "            genes = parts[2:] # Skip the gene set name and description\n",
    "            genesets [gene_set_name] = genes\n",
    "    return genesets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "899fac30-219e-4600-9257-44b795784b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'db/filtered.genesets.gmt' # Replace with your .gmt file path\n",
    "genesets = parse_gmt_file(file_path)\n",
    "\n",
    "for key in genesets: # some genesets have expression\n",
    "    genesets[key] = [e.split(\",\")[0] if \",\" in e else e for e in genesets[key]]\n",
    "\n",
    "for key in genesets:\n",
    "    genesets[key].append(\"<|end|>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "03f44051-bf4c-40cd-b8bc-3e6a81b599cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Pre-process the database to create a mapping dictionary\n",
    "def create_gene_mapping(db):\n",
    "    # Initialize a dictionary to hold the mapping\n",
    "    gene_mapping = {}\n",
    "    \n",
    "    # Add direct symbol mappings\n",
    "    for _, row in db.iterrows():\n",
    "\n",
    "        gene = row['symbol']\n",
    "        gene_mapping[gene] = []\n",
    "        \n",
    "        # Add alias symbol mappings\n",
    "        if pd.notna(row['alias_symbol']):\n",
    "            for alias in str(row['alias_symbol']).split('|'):\n",
    "                gene_mapping[gene].append(alias)\n",
    "        \n",
    "        # Add previous symbol mappings\n",
    "        if pd.notna(row['prev_symbol']):\n",
    "            for prev in str(row['prev_symbol']).split('|'):\n",
    "                gene_mapping[gene].append(prev)\n",
    "                \n",
    "    return gene_mapping\n",
    "\n",
    "# Function to harmonize genes in genesets_dict\n",
    "def harmonize_genesets(genesets_dict, gene_mapping, reversed_gene_mapping):\n",
    "    harmonized_genesets_dict = {}\n",
    "    i = 0\n",
    "    total_genesets = len(genesets)\n",
    "    \n",
    "    for geneset, genes in genesets_dict.items():\n",
    "        harmonized_genes = []\n",
    "        for gene in genes:\n",
    "\n",
    "            # check if it is updated\n",
    "            if gene in gene_mapping:\n",
    "                harmonized_genes.append(gene)\n",
    "            # if it is not harmonized\n",
    "            else:\n",
    "                # check if we can find a mapping\n",
    "                if gene in reversed_gene_mapping:\n",
    "                    harmonized_gene = reversed_gene_mapping[gene]\n",
    "                    if harmonized_gene in harmonized_genes:  # Avoid duplicates\n",
    "                        # print(\"Already in the harmonized list!\")\n",
    "                        continue\n",
    "                    else:\n",
    "                        #print(f\"New: {harmonized_gene}, old: {gene}\")\n",
    "                        harmonized_genes.append(harmonized_gene)\n",
    "                else:\n",
    "                    # print(f\"No match or mapping for {gene}\")\n",
    "                    harmonized_genes.append(gene)\n",
    "        harmonized_genesets_dict[geneset] = harmonized_genes\n",
    "\n",
    "        # print(len(genes), len(harmonized_genes))\n",
    "        i+=1\n",
    "        if i % (total_genesets // 10) == 0 or i == total_genesets:  # Update every 10%\n",
    "            print(f\"Processed {i}/{total_genesets} pathways...\")\n",
    "            \n",
    "    return harmonized_genesets_dict\n",
    "\n",
    "# Reverse the gene_mapping to facilitate alias/previous name lookup\n",
    "reversed_gene_mapping = {}\n",
    "for harmonized, aliases in gene_mapping.items():\n",
    "    for alias in aliases:\n",
    "        reversed_gene_mapping[alias] = harmonized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "d0f42fd9-94d8-406b-8d5f-0fa669c2c13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process the database to create the mapping\n",
    "gene_mapping = create_gene_mapping(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "52368c9b-9ce6-452a-b750-2b360fd6f6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 35111/351117 pathways...\n",
      "Processed 70222/351117 pathways...\n",
      "Processed 105333/351117 pathways...\n",
      "Processed 140444/351117 pathways...\n",
      "Processed 175555/351117 pathways...\n",
      "Processed 210666/351117 pathways...\n",
      "Processed 245777/351117 pathways...\n",
      "Processed 280888/351117 pathways...\n",
      "Processed 315999/351117 pathways...\n",
      "Processed 351110/351117 pathways...\n",
      "Processed 351117/351117 pathways...\n"
     ]
    }
   ],
   "source": [
    "genesets_harmonized = harmonize_genesets(genesets, gene_mapping, reversed_gene_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "e4d204f7-9335-4a87-8a98-3fe31c0833ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "harmonized_gene_perc_per_pathway = {}\n",
    "for key in updated_genesets_harmonized:\n",
    "    harmonized_genes_count = 0\n",
    "    # Check each gene to see if it's in the reversed_gene_mapping\n",
    "    for gene in genesets_harmonized[key]:\n",
    "        if gene in gene_mapping:\n",
    "            harmonized_genes_count += 1\n",
    "    harmonized_gene_perc_per_pathway[key] = harmonized_genes_count/len(genesets_harmonized[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "3bce9ef4-4851-4499-9a9c-d334e2cbe59e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126551"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AFTER GENE NOMENCLATURE \n",
    "# Flatten all gene lists into a single list\n",
    "data = [gene for genes in genesets_harmonized.values() for gene in genes]\n",
    "# Use Counter to count occurrences of each gene\n",
    "tokens = Counter(data)\n",
    "\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "3b7317e0-615e-4b18-8564-8ea79459c16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_genes = [key for key, value in tokens.items() if value > 5] # select genes occuring more than 5 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "c45ba060-53d1-4fe1-afd4-5e3d9ce0e348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert filtered_genes to a set for faster lookup\n",
    "filtered_genes_set = set(filtered_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "b2af3635-6721-4307-b6ac-05b6a50b6ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New dictionary to hold the updated genesets, optimized for speed\n",
    "updated_genesets_harmonized = {}\n",
    "\n",
    "for geneset, genes in genesets_harmonized.items():\n",
    "    # Use the set for faster 'in' checks\n",
    "    updated_genes = [gene for gene in genes if gene in filtered_genes_set]\n",
    "    updated_genesets_harmonized[geneset] = updated_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "cc0e8b06-d4e7-4cf9-b657-f44f798c745a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Function to count harmonized genes in each geneset\n",
    "def perc_harmonized_genes_in_genesets(genesets_dict, map):\n",
    "    count_dict = {}\n",
    "    for geneset, genes in genesets_dict.items():\n",
    "        # Initialize the count for this geneset\n",
    "        harmonized_genes_count = 0\n",
    "        \n",
    "        # Check each gene to see if it's in the reversed_gene_mapping\n",
    "        for gene in genes:\n",
    "            if gene in map:\n",
    "                harmonized_genes_count += 1\n",
    "                \n",
    "        # Store the count for this geneset\n",
    "        count_dict[geneset] = harmonized_genes_count/len(genes)*100\n",
    "    \n",
    "    return count_dict\n",
    "\n",
    "perc = perc_harmonized_genes_in_genesets(updated_genesets_harmonized, gene_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "249d160a-03bf-408d-afe9-cea1da746fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55340"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AFTER GENE NOMENCLATURE and TOKEN filtering\n",
    "# Flatten all gene lists into a single list\n",
    "data = [gene for genes in updated_genesets_harmonized.values() for gene in genes]\n",
    "# Use Counter to count occurrences of each gene\n",
    "tokens = Counter(data)\n",
    "\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "799e1c4a-e3ac-4e5c-bdf5-ef8b21b13c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_keys = {key: value for key, value in perc.items() if value >= 90} # select high-quality human pathways\n",
    "selected_genesets = {key: updated_genesets_harmonized[key] for key in selected_keys if key in updated_genesets_harmonized}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "0bf36c5f-c89b-43ea-851d-a2854b26793e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44902"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AFTER GENE NOMENCLATURE and TOKEN filtering and removing shitty pathways\n",
    "# Flatten all gene lists into a single list\n",
    "data = [gene for genes in selected_genesets.values() for gene in genes]\n",
    "# Use Counter to count occurrences of each gene\n",
    "tokens = Counter(data)\n",
    "\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "f813921a-4ade-4671-95ee-a69e983a88d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sample size: 351117\n",
      "After sample size: 263730\n"
     ]
    }
   ],
   "source": [
    "print(f\"Before sample size: {len(updated_genesets_harmonized)}\\nAfter sample size: {len(selected_genesets)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "3cc1e50b-3adb-4ec2-839a-09c032c01bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(tokens) }\n",
    "itos = { i:ch for i,ch in enumerate(tokens) }\n",
    "def encode(s):\n",
    "    return [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "def decode(l):\n",
    "    return ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "7452b0cc-7777-4741-8bbf-32111f430b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size: 44,902\n",
      "train has 47,316,670 tokens\n",
      "val has 2,490,352 tokens\n"
     ]
    }
   ],
   "source": [
    "# create the train and test splits\n",
    "n = len(data)\n",
    "train_data = data[:int(n*0.95)]\n",
    "val_data = data[int(n*0.95):]\n",
    "\n",
    "# encode both to integers\n",
    "train_ids = encode(train_data)\n",
    "val_ids = encode(val_data)\n",
    "\n",
    "vocab_size = len(tokens)\n",
    "print(f\"vocab size: {vocab_size:,}\")\n",
    "print(f\"train has {len(train_ids):,} tokens\")\n",
    "print(f\"val has {len(val_ids):,} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "aa8d4644-c36e-4c28-aaa9-39317baf282b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_dict = {key: value for key, value in selected_genesets.items() if \"GSE149609\" in key}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "d88d47ec-cfaf-45f7-a931-04b2d7cd3e19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10019"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of pathways\n",
    "Counter(val_data)['<|end|>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "2fa38022-e308-440d-a466-e052d55fdc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random_validation_set = list(selected_genesets.items())[-1000:]\n",
    "random_validation_set = dict(random_validation_set)\n",
    "\n",
    "with open('random_val_1000.pkl', 'wb') as f:\n",
    "    pickle.dump(random_validation_set, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "624d414d-e001-443a-84fe-82d5fd902f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import osd\n",
    "import pickle\n",
    "\n",
    "# __file__ = '.'\n",
    "\n",
    "# export to bin files\n",
    "train_ids = np.array(train_ids, dtype=np.uint16)\n",
    "val_ids = np.array(val_ids, dtype=np.uint16)\n",
    "train_ids.tofile(os.path.join(os.path.dirname(__file__), 'train.bin'))\n",
    "val_ids.tofile(os.path.join(os.path.dirname(__file__), 'val.bin'))\n",
    "\n",
    "# save the meta information as well, to help us encode/decode later\n",
    "meta = {\n",
    "    'vocab_size': vocab_size,\n",
    "    'itos': itos,\n",
    "    'stoi': stoi,\n",
    "}\n",
    "with open(os.path.join(os.path.dirname(__file__), 'meta.pkl'), 'wb') as f:\n",
    "    pickle.dump(meta, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
